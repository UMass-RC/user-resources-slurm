#!/usr/bin/env python3
DESCRIPTION = """
displays the allocation of all GPU's in slurm, grouped by GPU model.
Define SINFO_CACHE_FILE=none to disable caching.
If the "foobar" GPU has "123,456" in its VRAM column, that means that you can
use "-G foobar -C vram123" or "-G foobar -C vram456" in your slurm arguments.
"""
import re
import os
import sys
import json
import argparse
import subprocess as subp  # nosec
from typing import List

SINFO_CACHE_FILE = "/modules/user-resources/cache/sinfo-N.json"
DOWN_STATES = {"DOWN", "DRAIN", "NOT_RESPONDING"}
ALLOC_STATES = {"ALLOCATED", "MIXED"}
MY_FILENAME = os.path.split(sys.argv[0])[-1]

COLUMN_HEADERS = ["Type", "Allocated", "Pending", "VRAM", "CC"]
COLUMN_HEADERS_LOWER = [x.lower() for x in COLUMN_HEADERS]

PARTITION2GPU = {
    "umd-cscdr-gpu": "a100",
    "gpupod-l40s": "l40s",
    "superpod-a100": "a100",
    "ials-gpu": "2080ti",
    "lan": "a40",
    "power9-gpu": "v100",
    "power9-gpu-osg": "v100",
    "power9-gpu-preempt": "v100",
}


def guess_gpu(job):
    return PARTITION2GPU.get(job["partition"], "unknown")


def quotient_between_0_1(num, den):
    assert not (num > den)
    assert (num >= 0) and (den >= 0)
    if num == 0 and den == 0:
        return 0
    # throws ZeroDivisionError for 0 den
    return num / den


def closest_element_index(_list, target) -> int:
    """
    return the index of the list element which is closest to target
    """
    min_diff = None
    min_diff_index = -1
    for i, element in enumerate(_list):
        diff = element - target
        if i == 0 or abs(diff) < abs(min_diff):
            min_diff = diff
            min_diff_index = i
    return min_diff_index


def generate_progress_bar(frac: float, _len=20) -> str:
    assert frac >= 0 and frac <= 1
    _len -= 2  # subtract beginning and end characters
    num_chars2frac = [x / _len for x in range(_len + 1)]  # [ 0, 1/len, 2/len, ... len/len=1 ]
    num_chars = closest_element_index(
        num_chars2frac, frac
    )  # round `frac` to the nearest character length fraction
    progress_bar = "[" + ("#" * num_chars) + (" " * (_len - num_chars)) + "]"
    return progress_bar


def fmt_table(
    table, between_column_padding_size=5, alternate_brightness=True, left_padding_size=0
) -> List[str]:
    """
    I would use tabulate but I don't want nonstandard imports
    """
    output_lines = []
    assert all(
        len(row) <= len(table[0]) for row in table
    ), "no row can have more elements than the header row"
    column_widths = [0] * len(table[0])
    for row in table:
        for i, element in enumerate(row):
            if len(str(element)) > column_widths[i]:
                column_widths[i] = len(str(element))
    column_widths = [x + between_column_padding_size for x in column_widths]
    header = ""
    for i, column_header in enumerate(table[0]):
        if i > 0:
            header += "|"
        header += str(column_header).center(column_widths[i] - 1)  # minus one for the '|'
    output_lines.append(header)
    output_lines.append("".join(["="] * len(header)))
    for row in table[1:]:
        if left_padding_size > 0:
            line = " " * left_padding_size
        else:
            line = ""
        for i, value in enumerate(row):
            line = line + str(value).ljust(column_widths[i])
        output_lines.append(line)
    if alternate_brightness:
        bright = "\033[0;1m"
        reset = "\033[0m"
        for i, line in enumerate(output_lines):
            if i <= 1:
                continue  # skip first 2 lines
            if i % 2 == 0:
                output_lines[i] = bright + line + reset

    return output_lines


def get_gpu_specs_from_node_features(sinfo_node: dict) -> dict:
    highest_vram = -1
    highest_cc = -1
    for feature in sinfo_node["features"]["active"].split(","):
        sm_match = re.fullmatch(r"sm_(\d+)", feature)
        if sm_match:
            [this_sm] = sm_match.groups()
            this_cc = int(this_sm) / 10  # sm_55 -> CC=5.5
            highest_cc = max(highest_cc, this_cc)
        vram_match = re.fullmatch(r"vram(\d+)", feature)
        if vram_match:
            [this_vram] = vram_match.groups()
            this_vram = int(this_vram)
            highest_vram = max(highest_vram, this_vram)
    assert (
        highest_vram != -1 and highest_cc != -1
    ), "node must have at least one feature vramX and sm_X"
    return {"vram": highest_vram, "CC": highest_cc}


def gpu_name_remap(gpu_type):
    type_remap = {
        "2080_ti": "2080ti",
        "1080_ti": "1080ti",
        "rtx_8000": "rtx8000",
        "titan_x": "titanx",
    }
    if gpu_type in type_remap:
        gpu_type = type_remap[gpu_type]
    return gpu_type


def main():
    parser = argparse.ArgumentParser(description=DESCRIPTION)
    parser.add_argument(
        "--sort",
        choices=["total", "cc/vram", "free", "type"],
        default="cc/vram",
        help='"any" and "unknown" are at the top of the table regardless of sorting',
    )
    args = parser.parse_args()

    print("collecting info from slurm...", file=sys.stderr, end="", flush=True)
    if SINFO_CACHE_FILE.lower() != "none" and os.path.isfile(SINFO_CACHE_FILE):
        with open(SINFO_CACHE_FILE, "r", encoding="utf8") as file:
            sinfo = json.load(file)
    else:
        sinfo = json.loads(subp.check_output(["/usr/bin/sinfo", "--all", "-N", "--json"]))  # nosec
    squeue = json.loads(subp.check_output(["/usr/bin/squeue", "--json"]))  # nosec
    print("done", file=sys.stderr, flush=True)

    nodes = set()
    down_nodes = set()
    gpus = {}
    # type: spec_name: set of spec values
    gpu_specs = {"any": {"vram": {0}, "CC": {0}}, "unknown": {"vram": {0}, "CC": {0}}}

    def add_gpus(gpu_type: str, allocation_type: str, gpu_count: int):
        if isinstance(gpu_count, str):
            gpu_count = int(gpu_count)
        if gpu_type != "any":
            add_gpus("any", allocation_type, gpu_count)
        if gpu_type not in gpus:
            gpus[gpu_type] = {"total": 0, "allocated": 0, "pending": 0}
        gpus[gpu_type][allocation_type] += gpu_count

    for sinfo_node in sinfo["sinfo"]:
        name = sinfo_node["nodes"]["nodes"][0]
        if name in nodes or name in down_nodes:
            continue
        if any([state in DOWN_STATES for state in sinfo_node["node"]["state"]]) and not any(
            [state in ALLOC_STATES for state in sinfo_node["node"]["state"]]
        ):
            down_nodes.add(name)
        else:
            nodes.add(name)
        for resource in sinfo_node["gres"]["total"].split(","):
            if resource.startswith("gpu:"):
                # gpu:2080_ti:8(S:0-1)
                # https://github.com/SchedMD/slurm/blob/51b5f5bcb8704a56cc58c56f02cb81bb3346636d/src/interfaces/gres.c#L4361
                resource = re.sub(r"\(S:[\d-]+\)$", "", resource)
                [_, gpu_type, gpu_count] = resource.split(":")
                gpu_type = gpu_name_remap(gpu_type)
                add_gpus(gpu_type, "total", gpu_count)
                this_gpu_specs = get_gpu_specs_from_node_features(sinfo_node)
                for spec_name, spec_value in this_gpu_specs.items():
                    if gpu_type not in gpu_specs:
                        gpu_specs[gpu_type] = {}
                    if spec_name not in gpu_specs[gpu_type]:
                        gpu_specs[gpu_type][spec_name] = set()
                    gpu_specs[gpu_type][spec_name].add(spec_value)

    # once all values for gpu specs have been added, sort
    for gpu_type, specs in gpu_specs.items():
        for spec_name, spec_values in specs.items():
            gpu_specs[gpu_type][spec_name] = sorted(list(spec_values), reverse=True)

    for job in squeue["jobs"]:
        if "RUNNING" in job["job_state"]:
            allocation_type = "allocated"
            tres_str = "tres_alloc_str"
        elif "PENDING" in job["job_state"]:
            allocation_type = "pending"
            tres_str = "tres_req_str"
        else:
            continue
        total_specific_gpus = 0
        total_generic_gpus = 0
        # example: "cpu=4,mem=40G,node=1,billing=1,gres/gpu=1,gres/gpu:2080ti=1"
        for resource in job[tres_str].split(","):
            specific_match = re.fullmatch(r"gres/gpu:([^=]+)=(\d+)", resource)
            if specific_match:
                gpu_type, gpu_count = specific_match.groups()
                gpu_type = gpu_name_remap(gpu_type)
                total_specific_gpus += int(gpu_count)
                add_gpus(gpu_type, allocation_type, gpu_count)
                continue
            generic_match = re.fullmatch(r"gres/gpu=(\d+)", resource)
            if generic_match:
                [gpu_count] = generic_match.groups()
                total_generic_gpus += int(gpu_count)
                continue
        if total_specific_gpus == 0 and total_generic_gpus == 0:
            continue
        assert total_generic_gpus >= total_specific_gpus
        # unknown pending GPUs exist because the user did not specify a type
        # unknown allocated GPUs exist because slurm.conf doesn't know the GPU type:
        # AccountingStorageTRES=gres/gpu:<gpu-name>
        # where <gpu-name> was defined for a particular node like this:
        # NodeName=<hostname> ... Gres=gpu:<gpu-name>:<gpu-count>
        unknown_gpu_count = total_generic_gpus - total_specific_gpus
        if unknown_gpu_count > 0:
            add_gpus(guess_gpu(job), allocation_type, unknown_gpu_count)

    gpu_table = []
    for gpu_type, counts in gpus.items():
        if gpu_type == "unknown":
            # there is no "total" for "unknown" so don't give it a progress bar
            progress_bar_size = len(generate_progress_bar(0))
            allocated_str = f"{(' ' * progress_bar_size)} {counts['allocated']}"
        else:
            allocated_frac = quotient_between_0_1(counts["allocated"], counts["total"])
            allocated_str = (
                f'{generate_progress_bar(allocated_frac)} {counts["allocated"]}/{counts["total"]}'
            )
        gpu_table.append(
            [
                gpu_type,
                allocated_str,
                counts["pending"],
                ",".join([str(x) for x in gpu_specs[gpu_type]["vram"]]),
                ",".join([str(x) for x in gpu_specs[gpu_type]["CC"]]),
            ]
        )

    def gpu_table_get(row: list, column_name: str):
        column_index = COLUMN_HEADERS_LOWER.index(column_name.lower())
        return row[column_index]

    if args.sort == "cc/vram":
        gpu_table = sorted(
            gpu_table,
            reverse=True,
            key=lambda x: [gpu_table_get(x, "cc"), gpu_table_get(x, "vram")],
        )
    elif args.sort == "type":
        gpu_table = sorted(gpu_table, key=lambda x: gpu_table_get(x, "type"))
    elif args.sort == "total":

        def sort_func(x):
            name = gpu_table_get(x, "type")
            return gpus[name]["total"]

        gpu_table = sorted(gpu_table, reverse=True, key=sort_func)
    elif args.sort == "free":

        def sort_func(x):
            name = gpu_table_get(x, "type")
            return gpus[name]["total"] - gpus[name]["allocated"]

        gpu_table = sorted(gpu_table, reverse=True, key=sort_func)

    # move "unknown" to the top, then move "any" to the top
    for i, row in enumerate(gpu_table):
        if gpu_table_get(row, "type") == "unknown":
            gpu_table.insert(0, gpu_table.pop(i))
            break
    for i, row in enumerate(gpu_table):
        if gpu_table_get(row, "type") == "any":
            gpu_table.insert(0, gpu_table.pop(i))
            break

    gpu_table = [COLUMN_HEADERS] + gpu_table
    print()
    for line in fmt_table(gpu_table, alternate_brightness=False, left_padding_size=1):
        print(line)
    print()
    print(
        f" {len(down_nodes)} nodes are inacessible, and their GPUs have not been added to totals."
    )
    print()


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
displays the allocation of all GPU's in slurm, grouped by GPU model
define SINFO_CACHE_FILE=none to disable caching
"""
import os
import sys
import json
import subprocess as subp  # nosec

SINFO_CACHE_FILE = "/modules/user-resources/cache/sinfo-N.json"
DOWN_STATES = {"DOWN", "DRAIN", "NOT_RESPONDING"}
ALLOC_STATES = {"ALLOCATED", "MIXED"}
MY_FILENAME = os.path.split(sys.argv[0])[-1]


def divide_allow_zero(num, den):
    if num == 0 and den == 0:
        return 0
    if den == 0:
        return 1
    return num / den


def closest_element_index(_list, target) -> int:
    """
    return the index of the list element which is closest to target
    """
    min_diff = None
    min_diff_index = -1
    for i, element in enumerate(_list):
        diff = element - target
        if i == 0 or abs(diff) < abs(min_diff):
            min_diff = diff
            min_diff_index = i
    return min_diff_index


def generate_progress_bar(frac: float, _len=20) -> str:
    assert frac >= 0 and frac <= 1
    _len -= 2  # subtract beginning and end characters
    num_chars2frac = [x / _len for x in range(_len + 1)]  # [ 0, 1/len, 2/len, ... len/len=1 ]
    num_chars = closest_element_index(
        num_chars2frac, frac
    )  # round `frac` to the nearest character length fraction
    progress_bar = "[" + ("#" * num_chars) + (" " * (_len - num_chars)) + "]"
    return progress_bar


def fmt_table(table) -> str:
    """
    I would use tabulate but I don't want nonstandard imports
    """
    table_output = ""
    # no row has more elements than the header row
    assert all(len(row) <= len(table[0]) for row in table)
    column_widths = [0] * len(table[0])
    for row in table:
        for i, element in enumerate(row):
            if len(str(element)) > column_widths[i]:
                column_widths[i] = len(str(element))
    column_widths = [x + 3 for x in column_widths]  # room for whitespace on either side
    table_output += "\033[4m"  # start underline
    for i, column_header in enumerate(table[0]):
        if i > 0:
            table_output += "|"
        table_output += str(column_header).center(column_widths[i] - 1)  # minus one for the '|'
    table_output += "\033[0m"  # end underline
    table_output += "\n"
    for row in table[1:]:
        for i, value in enumerate(row):
            table_output += str(value).ljust(column_widths[i])
        table_output += "\n"
    return table_output


def add_gpus(gpu_type: str, allocation_type: str, gpu_count: int):
    if isinstance(gpu_count, str):
        gpu_count = int(gpu_count)
    if gpu_type not in gpus:
        gpus[gpu_type] = {"total": 0, "allocated": 0, "pending": 0}
    gpus[gpu_type][allocation_type] += gpu_count


print("collecting info from slurm...", file=sys.stderr, end="", flush=True)
if SINFO_CACHE_FILE.lower() != "none" and os.path.isfile(SINFO_CACHE_FILE):
    with open(SINFO_CACHE_FILE, "r", encoding="utf8") as file:
        sinfo = json.load(file)
else:
    sinfo = json.loads(subp.check_output(["/usr/bin/sinfo", "--all", "-N", "--json"]))  # nosec
squeue = json.loads(subp.check_output(["/usr/bin/squeue", "--json"]))  # nosec
print("done", file=sys.stderr, flush=True)

nodes = set()
down_nodes = set()
gpus = {}
for sinfo_node in sinfo["sinfo"]:
    name = sinfo_node["nodes"]["nodes"][0]
    if name in nodes or name in down_nodes:
        continue
    if any([state in DOWN_STATES for state in sinfo_node["node"]["state"]]) and not any(
        [state in ALLOC_STATES for state in sinfo_node["node"]["state"]]
    ):
        down_nodes.add(name)
    else:
        nodes.add(name)
    for resource in sinfo_node["gres"]["total"].split(","):
        if resource.startswith("gpu:"):
            [_, gpu_type, gpu_count] = resource.split(":")
            add_gpus(gpu_type, "total", gpu_count)


def guess_gpu(job):
    # Map partitions with only one type of GPU to that type
    gpu_part_map = {
        "gypsum-rtx8000": "rtx8000",
        "gypsum-m40": "m40",
        "gypsum-2080ti": "2080ti",
        "gypsum-1080ti": "1080ti",
        "gypsum-titanx": "titanx",
        "uri-gpu": "a100",
        "umd-cscdr-gpu": "a100",
        "hgx-alpha": "a100",
        "ials-gpu": "2080ti",
        "lan": "a40",
        "power9-gpu": "v100",
        "power9-gpu-osg": "v100",
        "power9-gpu-preempt": "v100",
    }
    # List of features (or partial features) to match
    gpu_types = [
        "a40",
        "a100",
        "v100",
        "titanx",
        "rtx8000",
        "m40",
        "2080",
        "2080ti",
        "1080ti",
    ]
    if job["partition"] in gpu_part_map:
        return gpu_part_map[job["partition"]]
    for x in gpu_types:
        if x in job["features"]:
            return x
    return "any"


for job in squeue["jobs"]:
    if job["job_state"] == "RUNNING":
        allocation_type = "allocated"
        tres_str = "tres_alloc_str"
    elif job["job_state"] == "PENDING":
        allocation_type = "pending"
        tres_str = "tres_req_str"
    else:
        continue
    # example: "cpu=4,mem=40G,node=1,billing=1,gres/gpu=1,gres/gpu:2080ti=1"
    #   Reverse list to ensure specific type is picked up first
    for resource in reversed(job[tres_str].split(",")):
        generic_gpus_counted = 0
        specific_gpus_counted = 0
        gpu_type = None
        if resource.startswith("gres/gpu:"):
            [gpu_type, gpu_count] = resource.replace("gres/gpu:", "").split("=")
            generic_gpus_counted += int(gpu_count)
        elif resource.startswith("gres/gpu="):
            gpu_type = guess_gpu(job)
            [_, gpu_count] = resource.split("=")
            specific_gpus_counted += int(gpu_count)
        if gpu_type:
            add_gpus(gpu_type, allocation_type, gpu_count)
            break  # only record one gpu type per job
    # if generic_gpus_counted > specific_gpus_counted:
    #    # if you want to reduce the number of unknown GPUs, you need to add this:
    #    # AccountingStorageTRES=gres/gpu:<gpu-name>
    #    # to your slurm.conf, where <gpu-name> was defined for a particular node like this:
    #    # NodeName=<hostname> ... Gres=gpu:<gpu-name>:<gpu-count>
    #    add_gpus(
    #        "unknown", allocation_type, (generic_gpus_counted - specific_gpus_counted)
    #    )


def get_all_gpus():
    for item in sinfo["sinfo"]:
        if item["partition"]["name"] == "building":
            configured_tres = item["partition"]["tres"]["configured"]
            for gres in configured_tres.split(","):
                if gres.startswith("gres/gpu="):
                    return int(gres.split("=")[1])


gpus["any"] = {"allocated": 0, "pending": 0}
gpus["any"]["total"] = get_all_gpus()
gpu_table = []
# for gpu_type,counts in gpus.items():
#     gpu_table.append([gpu_type, counts["total"], counts["allocated"], counts["pending"]])
for gpu_type, counts in gpus.items():
    allocated_frac = divide_allow_zero(counts["allocated"], counts["total"])
    pending_frac = divide_allow_zero(counts["pending"], counts["total"])
    gpu_table.append(
        [
            gpu_type,
            f'{generate_progress_bar(allocated_frac)} {counts["allocated"]}/{counts["total"]}',
            f'{generate_progress_bar(pending_frac)} {counts["pending"]}',
        ]
    )
gpu_table = sorted(
    gpu_table, reverse=True, key=lambda x: gpus[x[0]]["total"]
)  # sort table based on "total"
gpu_table = [["GPU type", "Allocated", "Pending"]] + gpu_table  # add column headers
table_str = fmt_table(gpu_table)
table_str_padded_left = "\n".join([" " + line for line in table_str.splitlines()])
print()
print(table_str_padded_left)
print()
print(f" {len(down_nodes)} nodes are inacessible, and their GPUs have not been added to totals.")
print()
